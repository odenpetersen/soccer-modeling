{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230d229c",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Predict: Class of event -> Class of next event\n",
    "  - simple biased predictor\n",
    "  - hierarchical bayes predictor\n",
    "- Predict: All features -> Class of next event\n",
    "  - decision tree\n",
    "  - random forest\n",
    "  - random forest adaboosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d31c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  subEventName              tags       positions  matchId  \\\n",
      "0                0   Simple pass      ['Accurate']  (51.45, 33.32)  2499719   \n",
      "1              901   Simple pass      ['Accurate']    (52.5, 34.0)  2499719   \n",
      "2                1     High pass      ['Accurate']  (32.55, 53.04)  2499719   \n",
      "3              902     High pass  ['Not accurate']   (65.1, 39.44)  2499719   \n",
      "4                2     Head pass      ['Accurate']   (53.55, 51.0)  2499719   \n",
      "...            ...           ...               ...             ...      ...   \n",
      "643145      642431   Simple pass      ['Accurate']    (44.1, 6.12)  2500098   \n",
      "643146      642432     High pass      ['Accurate']   (12.6, 31.28)  2500098   \n",
      "643147      642433  Acceleration      ['Accurate']   (27.3, 61.88)  2500098   \n",
      "643148      642434   Simple pass      ['Accurate']   (63.0, 65.28)  2500098   \n",
      "643149      642435   Simple pass  ['Not accurate']  (43.05, 56.44)  2500098   \n",
      "\n",
      "                 eventName  teamId matchPeriod     eventSec         id  ...  \\\n",
      "0                     Pass    1609          1H     2.758649  177959171  ...   \n",
      "1                     Pass    1631          2H     2.836169  177960135  ...   \n",
      "2                     Pass    1609          1H     4.946850  177959172  ...   \n",
      "3                     Pass    1631          2H     5.311682  177960136  ...   \n",
      "4                     Pass    1609          1H     6.542188  177959173  ...   \n",
      "...                    ...     ...         ...          ...        ...  ...   \n",
      "643145                Pass    1633          1H  2922.201196  251595533  ...   \n",
      "643146                Pass    1633          1H  2929.045430  251595535  ...   \n",
      "643147  Others on the ball    1633          1H  2931.478354  251595536  ...   \n",
      "643148                Pass    1633          1H  2937.226346  251595537  ...   \n",
      "643149                Pass    1633          1H  2940.751065  251595538  ...   \n",
      "\n",
      "       seasonId              dateutc  winner             venue  \\\n",
      "0        181150  2017-08-11 18:45:00    1609  Emirates Stadium   \n",
      "1        181150  2017-08-11 18:45:00    1609  Emirates Stadium   \n",
      "2        181150  2017-08-11 18:45:00    1609  Emirates Stadium   \n",
      "3        181150  2017-08-11 18:45:00    1609  Emirates Stadium   \n",
      "4        181150  2017-08-11 18:45:00    1609  Emirates Stadium   \n",
      "...         ...                  ...     ...               ...   \n",
      "643145   181150  2018-05-13 14:00:00    1633    London Stadium   \n",
      "643146   181150  2018-05-13 14:00:00    1633    London Stadium   \n",
      "643147   181150  2018-05-13 14:00:00    1633    London Stadium   \n",
      "643148   181150  2018-05-13 14:00:00    1633    London Stadium   \n",
      "643149   181150  2018-05-13 14:00:00    1633    London Stadium   \n",
      "\n",
      "                                   label                                 date  \\\n",
      "0        Arsenal - Leicester City, 4 - 3  August 11, 2017 at 8:45:00 PM GMT+2   \n",
      "1        Arsenal - Leicester City, 4 - 3  August 11, 2017 at 8:45:00 PM GMT+2   \n",
      "2        Arsenal - Leicester City, 4 - 3  August 11, 2017 at 8:45:00 PM GMT+2   \n",
      "3        Arsenal - Leicester City, 4 - 3  August 11, 2017 at 8:45:00 PM GMT+2   \n",
      "4        Arsenal - Leicester City, 4 - 3  August 11, 2017 at 8:45:00 PM GMT+2   \n",
      "...                                  ...                                  ...   \n",
      "643145  West Ham United - Everton, 3 - 1     May 13, 2018 at 4:00:00 PM GMT+2   \n",
      "643146  West Ham United - Everton, 3 - 1     May 13, 2018 at 4:00:00 PM GMT+2   \n",
      "643147  West Ham United - Everton, 3 - 1     May 13, 2018 at 4:00:00 PM GMT+2   \n",
      "643148  West Ham United - Everton, 3 - 1     May 13, 2018 at 4:00:00 PM GMT+2   \n",
      "643149  West Ham United - Everton, 3 - 1     May 13, 2018 at 4:00:00 PM GMT+2   \n",
      "\n",
      "                                                 referees duration  \\\n",
      "0       [{'refereeId': 385909, 'role': 'referee'}, {'r...  Regular   \n",
      "1       [{'refereeId': 385909, 'role': 'referee'}, {'r...  Regular   \n",
      "2       [{'refereeId': 385909, 'role': 'referee'}, {'r...  Regular   \n",
      "3       [{'refereeId': 385909, 'role': 'referee'}, {'r...  Regular   \n",
      "4       [{'refereeId': 385909, 'role': 'referee'}, {'r...  Regular   \n",
      "...                                                   ...      ...   \n",
      "643145  [{'refereeId': 408156, 'role': 'referee'}, {'r...  Regular   \n",
      "643146  [{'refereeId': 408156, 'role': 'referee'}, {'r...  Regular   \n",
      "643147  [{'refereeId': 408156, 'role': 'referee'}, {'r...  Regular   \n",
      "643148  [{'refereeId': 408156, 'role': 'referee'}, {'r...  Regular   \n",
      "643149  [{'refereeId': 408156, 'role': 'referee'}, {'r...  Regular   \n",
      "\n",
      "        competitionId groupName  \n",
      "0                 364       NaN  \n",
      "1                 364       NaN  \n",
      "2                 364       NaN  \n",
      "3                 364       NaN  \n",
      "4                 364       NaN  \n",
      "...               ...       ...  \n",
      "643145            364       NaN  \n",
      "643146            364       NaN  \n",
      "643147            364       NaN  \n",
      "643148            364       NaN  \n",
      "643149            364       NaN  \n",
      "\n",
      "[643150 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_folder = \"../data\"\n",
    "contest = \"England\"\n",
    "\n",
    "df = pd.read_csv(f\"{data_folder}/parsed_{contest}.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38048ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# print(len(Counter(df.matchId)))\n",
    "# print(*sorted(Counter([tuple(x) for x in (df[['eventName', 'subEventName']].dropna().values)]).items(), key=lambda x: x[1], reverse=True), sep='\\n')\n",
    "\n",
    "# list(**chain.from_iterable(list(**df.tags)))\n",
    "alltags = [x for x in map(eval, list(df.tags))]\n",
    "# # print(Counter(chain.from_iterable(df.tags)))\n",
    "# Counter(chain.from_iterable(alltags))\n",
    "\n",
    "# 'Goal' in df.tags\n",
    "\n",
    "# df.tags\n",
    "count = 0\n",
    "for tags in alltags:\n",
    "    if 'Goal' in tags and 'Accurate' in tags:\n",
    "        count+= 1\n",
    "\n",
    "count\n",
    "# df['Goal' in df.tags]\n",
    "\n",
    "# Counter(alltags)\n",
    "# df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa84aea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_england = pd.read_json(\"../data/figshare/matches_England.json\")\n",
    "\n",
    "# teamss = matches_england['teamsData']\n",
    "\n",
    "# unformed_teams = set([teams[team]['hasFormation'] for teams in teamss for team in teams])\n",
    "# unformed_teams\n",
    "# unformed_teams[0]\n",
    "\n",
    "total = 0\n",
    "for label in matches_england['label']:\n",
    "    label = label.split()\n",
    "    a, b = int(label[-3]), int(label[-1])\n",
    "    total += a + b\n",
    "\n",
    "total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5bdb2",
   "metadata": {},
   "source": [
    "Priorities\n",
    "\n",
    "1. Probabilistic classification of the next event type/subtype/tags, given the most recent event details\n",
    "2. Regression/estimation of the expected waiting time until the next event, given the most recent event details\n",
    "    - most likely exponential\n",
    "3. A basic recursive predictive model\n",
    "4. Implementation of a Kalman filter to model ball position\n",
    "5. Putting this all into a nice looking report\n",
    "\n",
    "\n",
    "exponential distribution for the expected waiting time\n",
    "\n",
    "Regression problem, what are first and second moments of the position\n",
    "\n",
    "\n",
    "ideas\n",
    "- look into spatio-temporal methods\n",
    "\n",
    "William recommends making flowchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74e618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fde1dd5",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n",
    "quasi-constant variables = vairables that are mostly the same throughout\n",
    "\n",
    "havne't done much analysis yet\n",
    "written the abstract, know what we want to do\n",
    "- Don't know what to predict\n",
    "    - predicting winners\n",
    "        - one hot encoding\n",
    "        - get dummies\n",
    "        - too many tags to build encoding for\n",
    "        - sparse data, so support vector is ideal\n",
    "\n",
    "A lot of categorical features. This induces a lot of variance.\n",
    "- bagging sounds good to combat this\n",
    "\n",
    "time series data, CV-split is time-sensitive\n",
    "\n",
    "overview of the game of soccer\n",
    "\n",
    "key step is to clean the data\n",
    "\n",
    "we have code ready for us\n",
    "- gridsearch from labs\n",
    "- stuff on github\n",
    "    - we can use the metrics they've built\n",
    "\n",
    "\n",
    "Matthew says to eliminate constant and quasiconstant variables. \n",
    "eg. The acceleration index is almost always 0.\n",
    "\n",
    "randomised CV search ??\n",
    "\n",
    "\n",
    "structure-wise\n",
    "- feature engineering\n",
    "- \n",
    "- fit a basic model in\n",
    "- get a metric and evaluate it\n",
    "\n",
    "pick something that we're trying to predict/classify\n",
    "- who wins\n",
    "- what, when, and where the next event will be\n",
    "\n",
    "methods\n",
    "- oversampling and undersampling methods -> william's skilset. See if we can find something to predict\n",
    "    - who will win\n",
    "    - injuries\n",
    "        - red/yellow cards?\n",
    "    - \n",
    "\n",
    "build some simple models\n",
    "\n",
    "\n",
    "predict match outcomes from previous match data\n",
    "- use scores from previous matches\n",
    "    - collect data from wins/losses\n",
    "    - pick some simple models to apply to it\n",
    "        - performance score for each game?\n",
    "        - skill for each team?\n",
    "- use team \n",
    "- maybe position data\n",
    "- \n",
    "\n",
    "\n",
    "determine if players are playing particularly forward or backward compared to their position\n",
    "\n",
    "\n",
    "figure out what the distribution is for the first event, so that we can extrapolate for the rest of the match\n",
    "\n",
    "\n",
    "pretty graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df8b99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "logistic\n",
    "tuned\n",
    "plot roc uac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb931767",
   "metadata": {},
   "source": [
    "ideas\n",
    "\n",
    "Determine which directions let players keep the ball the longest\n",
    " - quad-tree\n",
    " - not sure how to make this machine-learning, it seems like a primarily statistical thing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2348d2",
   "metadata": {},
   "source": [
    "plan:\n",
    "- catch up on what's going on\n",
    "    - make notes on things to pay attention to\n",
    "- (babble) make a list of things that are possible to do in a day\n",
    "- prioritise and build a plan\n",
    "    - flesh out steps in detail\n",
    "- execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588effb6",
   "metadata": {},
   "source": [
    "# Analysis on past match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ff81b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "matches_england = pd.read_json(\"../data/figshare/matches_England.json\")\n",
    "\n",
    "# print(matches_england.iloc[0])\n",
    "\n",
    "def extract_match_results(matches):\n",
    "    def f(row):\n",
    "        # print(row)\n",
    "        teams, scores = row['label'].strip().split(',')\n",
    "        t1, t2 = teams.strip().split(' - ')\n",
    "        s1, s2 = map(int, scores.strip().split(' - '))\n",
    "        date = row['dateutc']\n",
    "        # return {'t1':t1, 't2':t2, 's1':s1, 's2':s2, 'date':date}\n",
    "        return {'s1': s1, 's2': s2, 'date': date, t1: 1, t2: -1}\n",
    "\n",
    "    results = matches.apply(f, axis=1)\n",
    "    # results = pd.DataFrame(results)\n",
    "\n",
    "    results = pd.DataFrame(list(results))\n",
    "    results = results.sort_values(by='date', axis=0).reset_index()\n",
    "    results = results.fillna(0)\n",
    "\n",
    "    return results\n",
    "\n",
    "# def one_hot_matches(results):\n",
    "\n",
    "\n",
    "results = extract_match_results(matches_england)\n",
    "teamnames = [team for team in results if team not in ['s1', 's2', 'date', 'index']]\n",
    "# print(teamnames)\n",
    "\n",
    "# teamnames = list(set(results.t1).union(results.t2))\n",
    "\n",
    "\n",
    "\n",
    "# teams = set()\n",
    "# for lineups in matches_england['teamsData']:\n",
    "#     for team in lineups.keys():\n",
    "#         teams.add(team)\n",
    "\n",
    "# print(teams)\n",
    "# matches_england\n",
    "\n",
    "# print(matches_england['teamsData'][0])\n",
    "# print(results)\n",
    "# print(results.iloc[8:20,:])\n",
    "for i in range(1, len(results)):\n",
    "    if results['date'][i] < results['date'][i-1]:\n",
    "        print(i)\n",
    "    \n",
    "# print(results['date'][10], results['date'][9], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9966a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy:  0.6666666666666666\n",
      "[[0.67784142 0.32215858]]\n",
      "2.7875103390440015\n",
      "Logistic regression accuracy:  0.6825396825396826\n",
      "[[0.203729 0.796271]]\n",
      "3.9818811591063024\n",
      "Logistic regression accuracy:  0.6349206349206349\n",
      "[[0.56312827 0.43687173]]\n",
      "2.663751545625254\n",
      "Logistic regression accuracy:  0.6507936507936508\n",
      "[[0.55584899 0.44415101]]\n",
      "2.3991456926077523\n",
      "Logistic regression accuracy:  0.5238095238095238\n",
      "[[0.48959046 0.51040954]]\n",
      "3.0482783891840044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "y, X = (results['s1'] - results['s2']).values, results[teamnames].values\n",
    "# print(y)\n",
    "# print(X)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index] #.reshape((-1, 1))\n",
    "    # print(y_train.shape)\n",
    "    clf = LogisticRegression(random_state=23).fit(X_train, (y_train > 0))\n",
    "    print(\"Logistic regression accuracy: \", clf.score(X_test, y_test > 0))\n",
    "    print(clf.predict_proba([[0]*len(teamnames)]))\n",
    "    # print(clf.intercept_, clf.coef_)\n",
    "\n",
    "    # clf = LogisticRegression(random_state=23).fit(X_train, (y_train > 0))\n",
    "    # print(\"Logistic regression accuracy: \", clf.score(X_test, y_test > 0))\n",
    "    # print(clf.predict_proba([[0]*len(teamnames)]))\n",
    "\n",
    "\n",
    "    lr: LinearRegression = LinearRegression().fit(X_train, y_train)\n",
    "    print(mse(y_test, lr.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "773bf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impl \n",
    "# def train_next_goal_home_prior_model(matches)\n",
    "\n",
    "# grab match data (done?)\n",
    "# train on \n",
    "\n",
    "\n",
    "def extract_teams_from_match(row):\n",
    "    # print(row)\n",
    "    # print(row['label'])\n",
    "    teams, _ = row['label'].strip().split(',')\n",
    "    t1, t2 = teams.strip().split(' - ')\n",
    "    return t1, t2\n",
    "\n",
    "# Predicts how many goals are expected of each team using a linear model, \n",
    "# and uses that to calculate the probability that the next goal is from the home team.\n",
    "def train_next_goal_home_prior_model(prior_matches):\n",
    "    results = extract_match_results(prior_matches)\n",
    "    teamnames = sorted([team for team in results if team not in ['s1', 's2', 'date', 'index']])\n",
    "\n",
    "    # doubling data by expressing it in terms of either team, with an extra column to track who is home\n",
    "    results['home'] = 1\n",
    "    y, X = results['s1'].values, results[['home'] + teamnames].values\n",
    "    y2, X2 = results['s2'].values, -results[['home'] + teamnames].values\n",
    "    y = np.concatenate([y, y2], axis=0)\n",
    "    X = np.concatenate([X, X2], axis=0)\n",
    "\n",
    "    lr: LinearRegression = LinearRegression().fit(X, y)\n",
    "\n",
    "    def format_match(match):\n",
    "        home, away = extract_teams_from_match(match)\n",
    "        return np.array([1] + [(team == home) - (team == away) for team in teamnames]).reshape((1, -1))\n",
    "\n",
    "    def predictor(match):\n",
    "        features_home = format_match(match)\n",
    "        expected_goals_home = lr.predict(features_home)\n",
    "        features_away = -format_match(match)\n",
    "        expected_goals_away = lr.predict(features_away)\n",
    "\n",
    "        return expected_goals_home / (expected_goals_home + expected_goals_away)\n",
    "\n",
    "    return predictor, lr, format_match\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a6d7f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  1]]\n",
      "[[ 1  0  0  0  0  0  1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  1]]\n",
      "[[ 1  0  1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0  0  1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  1 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 -1  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 -1  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 -1  0]]\n",
      "[[ 1  0  1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "[[ 1 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  1  0  0 -1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0  0  1  0  0  0  0 -1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  1  0  0  0  0  0 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  1]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 -1  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 -1]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0  0  0  0 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "[[ 1  0  0  0 -1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 -1  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "[[ 1  0  0  0  0  0  1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "[[ 1  0  0 -1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  1  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "[[ 1  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  0  0  0  0  1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0 -1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 -1  0  0]]\n",
      "[[ 1  0  0  1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 -1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  1  0  0  0]]\n",
      "[[ 1  0  0  0  0  1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "[[ 1  0  1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  1  0  0]]\n",
      "[[ 1  0  0 -1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 -1  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 -1  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  1  0  0  0  0  0 -1  0  0  0  0  0  0]]\n",
      "[[ 1 -1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  1  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  1]]\n",
      "[[ 1  0  0  0  0  0  0  0  0  0  0  0  0  1  0 -1  0  0  0  0  0]]\n",
      "[[ 1  0 -1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 -1  0  0]]\n",
      "190    [-0.23172596168043072]\n",
      "191    [-0.25624998036752605]\n",
      "192       [0.455819978067582]\n",
      "193       [2.344193631345281]\n",
      "194      [0.7018959038407834]\n",
      "                ...          \n",
      "375      [0.9540442484013649]\n",
      "376      [0.4483141177495079]\n",
      "377      [0.1570413241722674]\n",
      "378     [-0.8050733436584259]\n",
      "379      [0.7887278512614694]\n",
      "Length: 190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# test train_next_goal_home_prior_model()\n",
    "\n",
    "matches_england = pd.read_json(\"../data/figshare/matches_England.json\")\n",
    "first_matches, second_matches = matches_england.iloc[:len(matches_england)//2, :], matches_england.iloc[len(matches_england)//2:, :]\n",
    "\n",
    "predictor, model = train_next_goal_home_prior_model(first_matches)\n",
    "# print(second_matches.columns)\n",
    "\n",
    "\n",
    "predictions = second_matches.apply(predictor, axis=1)\n",
    "print(predictions)\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b7b41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expected_number_of_goals(prior_matches):\n",
    "    results = extract_match_results(prior_matches)\n",
    "    teamnames = sorted([team for team in results if team not in ['s1', 's2', 'date', 'index']])\n",
    "\n",
    "    # doubling data by expressing it in terms of either team, with an extra column to track who is home\n",
    "    results['home'] = 1\n",
    "    y, X = results['s1'].values, results[['home'] + teamnames].values\n",
    "    y2, X2 = results['s2'].values, -results[['home'] + teamnames].values\n",
    "    y = np.concatenate([y, y2], axis=0)\n",
    "    X = np.concatenate([X, X2], axis=0)\n",
    "\n",
    "    lr: LinearRegression = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "    return lambda match: lr.predict(match), lr\n",
    "\n",
    "\n",
    "\n",
    "def train_next_goal_home_prior_model(prior_matches):\n",
    "\n",
    "    expected_goals_predictor = train_expected_number_of_goals(prior_matches)\n",
    "\n",
    "    def format_match(match):\n",
    "        home, away = extract_teams_from_match(match)\n",
    "        return np.array([1] + [(team == home) - (team == away) for team in teamnames]).reshape((1, -1))\n",
    "\n",
    "    def predictor(match):\n",
    "        features_home = format_match(match)\n",
    "        print(features_home)\n",
    "        expected_goals_home = lr.predict(features_home)\n",
    "        features_away = -format_match(match)\n",
    "        expected_goals_away = lr.predict(features_away)\n",
    "\n",
    "        return expected_goals_home / (expected_goals_home + expected_goals_away)\n",
    "    \n",
    "    return predictor, expected_goals_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c158cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_predictions = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5bd44e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Index(['status', 'roundId', 'gameweek', 'teamsData', 'seasonId', 'dateutc',\n",
      "       'winner', 'venue', 'wyId', 'label', 'date', 'referees', 'duration',\n",
      "       'competitionId'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(teamnames))\n",
    "print(second_matches.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a937e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190    [0.18327900131420774]\n",
      "191    [0.09581262395525103]\n",
      "192     [1.0651950691756538]\n",
      "193      [3.273443520176269]\n",
      "194      [1.362293987586837]\n",
      "               ...          \n",
      "375      [1.596271692352814]\n",
      "376     [1.0565030012045236]\n",
      "377     [0.6769278472062048]\n",
      "378    [-0.5884750532876228]\n",
      "379     [1.5301470505975279]\n",
      "Length: 190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(predictions + old_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5453fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_waiting_time_prior_model(prior_matches):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    results = extract_match_results(prior_matches)\n",
    "    teamnames = sorted([team for team in results if team not in ['s1', 's2', 'date']])\n",
    "\n",
    "    # doubling data by expressing it in terms of either team, with an extra column to track who is home\n",
    "    results['home'] = 1\n",
    "    y, X = results['s1'].values, results[['home'] + teamnames].values\n",
    "    y2, X2 = results['s2'].values, -results[['home'] + teamnames].values\n",
    "    y = np.concatenate([y, y2], axis=0)\n",
    "    X = np.concatenate([X, X2], axis=0)\n",
    "\n",
    "    lr: LinearRegression = LinearRegression().fit(X, y)\n",
    "\n",
    "    def format_match(match):\n",
    "        home, away = extract_teams_from_match(match)\n",
    "        return np.array([1] + [(team == home) - (team == away) for team in teamnames]).reshape((1, -1))\n",
    "\n",
    "    def predictor(match):\n",
    "        features_home = format_match(match)\n",
    "        expected_goals_home = lr.predict(features_home)\n",
    "        features_away = -format_match(match)\n",
    "        expected_goals_away = lr.predict(features_away)\n",
    "\n",
    "        return expected_goals_home / (expected_goals_home + expected_goals_away)\n",
    "\n",
    "    return predictor, lr, format_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c9b44ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Burnley',\n",
       " 'AFC Bournemouth',\n",
       " 'Crystal Palace',\n",
       " 'West Bromwich Albion',\n",
       " 'Huddersfield Town',\n",
       " 'Arsenal',\n",
       " 'Liverpool',\n",
       " 'Brighton & Hove Albion',\n",
       " 'Manchester United',\n",
       " 'Watford',\n",
       " 'Newcastle United',\n",
       " 'Chelsea',\n",
       " 'Southampton',\n",
       " 'Manchester City',\n",
       " 'Swansea City',\n",
       " 'Stoke City',\n",
       " 'Tottenham Hotspur',\n",
       " 'Leicester City',\n",
       " 'West Ham United',\n",
       " 'Everton']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamnames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('soccer-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2054d55dd70d5b446ed4bf56b3105c2eea46c8cf09744ab2ca1bd8f8e178d281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
